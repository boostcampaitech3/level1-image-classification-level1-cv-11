{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 11\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True # 고정하면 학습이 느려진다고 합니다.\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/data/train/train_new.csv')\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify = df['sex'], random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'age'\n",
    "MASK_CLASS_NUM = 3\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "train_data = dataset.MaskDataset(train_df,target,transform)\n",
    "valid_data = dataset.MaskDataset(valid_df,target,transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_data,batch_size=16,shuffle=True)\n",
    "valid_iter = DataLoader(valid_data,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 필요 입력 채널 개수 3\n",
      "네트워크 출력 채널 개수 (예측 class type 개수) 3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# ImageNet에서 학습된 ResNet 18 딥러닝 모델을 불러옴\n",
    "imagenet_resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "# 분류 모델의 output 크기가 1000개로 되어 있음으로 mnist data class 개수로 나올 수 있도록 Fully Connected Layer를 변경하고 xavier uniform으로 weight 초기화\n",
    "imagenet_resnet18.fc = torch.nn.Linear(in_features=512, out_features=MASK_CLASS_NUM, bias=True)\n",
    "torch.nn.init.xavier_uniform_(imagenet_resnet18.fc.weight)\n",
    "stdv = 1. / math.sqrt(imagenet_resnet18.fc.weight.size(1))\n",
    "imagenet_resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "print(\"네트워크 필요 입력 채널 개수\", imagenet_resnet18.conv1.weight.shape[1])\n",
    "print(\"네트워크 출력 채널 개수 (예측 class type 개수)\", imagenet_resnet18.fc.weight.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is using!\n"
     ]
    }
   ],
   "source": [
    "#Hyper Parameters\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 학습 때 GPU 사용여부 결정. Colab에서는 \"런타임\"->\"런타임 유형 변경\"에서 \"GPU\"를 선택할 수 있음\n",
    "\n",
    "print(f\"{device} is using!\")\n",
    "\n",
    "imagenet_resnet18.to(device) # Resnent 18 네트워크의 Tensor들을 GPU에 올릴지 Memory에 올릴지 결정함\n",
    "\n",
    "LEARNING_RATE = 0.0001 # 학습 때 사용하는 optimizer의 학습률 옵션 설정\n",
    "NUM_EPOCH = 3 # 학습 때 mnist train 데이터 셋을 얼마나 많이 학습할지 결정하는 옵션\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # 분류 학습 때 많이 사용되는 Cross entropy loss를 objective function으로 사용 - https://en.wikipedia.org/wiki/Cross_entropy\n",
    "optimizer = torch.optim.Adam(imagenet_resnet18.parameters(), lr=LEARNING_RATE) # weight 업데이트를 위한 optimizer를 Adam으로 사용함\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : train_iter,\n",
    "    \"test\" : valid_iter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [03:10<00:00,  4.96it/s]\n",
      "  0%|          | 1/237 [00:00<00:28,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 train-데이터 셋에서 평균 Loss : 0.198, 평균 Accuracy : 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:31<00:00,  7.53it/s]\n",
      "  0%|          | 0/945 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-0의 test-데이터 셋에서 평균 Loss : 0.076, 평균 Accuracy : 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [03:09<00:00,  4.99it/s]\n",
      "  0%|          | 1/237 [00:00<00:28,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 train-데이터 셋에서 평균 Loss : 0.055, 평균 Accuracy : 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:31<00:00,  7.59it/s]\n",
      "  0%|          | 1/945 [00:00<03:06,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-1의 test-데이터 셋에서 평균 Loss : 0.065, 평균 Accuracy : 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [03:06<00:00,  5.06it/s]\n",
      "  0%|          | 1/237 [00:00<00:28,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 train-데이터 셋에서 평균 Loss : 0.035, 평균 Accuracy : 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:31<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 epoch-2의 test-데이터 셋에서 평균 Loss : 0.034, 평균 Accuracy : 0.988\n",
      "학습 종료!\n",
      "최고 accuracy : 0.988359808921814, 최고 낮은 loss : 0.03404399656946894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, notebook\n",
    "\n",
    "### 학습 코드 시작\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "  for phase in [\"train\", \"test\"]:\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    if phase == \"train\":\n",
    "      imagenet_resnet18.train() # 네트워크 모델을 train 모드로 두어 gradient을 계산하고, 여러 sub module (배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "    elif phase == \"test\":\n",
    "      imagenet_resnet18.eval() # 네트워크 모델을 eval 모드 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "\n",
    "    for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "      # (참고.해보기) 현재 tqdm으로 출력되는 것이 단순히 진행 상황 뿐인데 현재 epoch, running_loss와 running_acc을 출력하려면 어떻게 할 수 있는지 tqdm 문서를 보고 해봅시다!\n",
    "      # hint - with, pbar\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함\n",
    "\n",
    "      with torch.set_grad_enabled(phase == \"train\"): # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "        logits = imagenet_resnet18(images)\n",
    "        _, preds = torch.max(logits, 1) # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 최대 output index를 찾아 예측 레이블([2])로 변경함  \n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        if phase == \"train\":\n",
    "          loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "          optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "\n",
    "      running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "      running_acc += torch.sum(preds == labels.data) # 한 Batch에서의 Accuracy 값 저장\n",
    "\n",
    "    # 한 epoch이 모두 종료되었을 때,\n",
    "    epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "    epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "    print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n",
    "    if phase == \"test\" and best_test_accuracy < epoch_acc: # phase가 test일 때, best accuracy 계산\n",
    "      best_test_accuracy = epoch_acc\n",
    "    if phase == \"test\" and best_test_loss > epoch_loss: # phase가 test일 때, best loss 계산\n",
    "      best_test_loss = epoch_loss\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(imagenet_resnet18.state_dict(), f'./model/{target}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
